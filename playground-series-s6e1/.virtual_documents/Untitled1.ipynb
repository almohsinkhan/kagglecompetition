import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures


train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')


# let's separate numeric columns and categorical columns 
num_cols = train.select_dtypes(include=np.number).columns.tolist()
num_cols.remove('id')
cat_cols = train.select_dtypes(include = ['object', 'string']).columns.tolist()


num_features = ['study_hours', 'class_attendance', 'sleep_hours']
cat_features = cat_cols   # your categorical columns

X = train[num_features + cat_features]
y = train['exam_score']


preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), num_features),
        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features)
    ]
)


pipeline = Pipeline(steps=[
    ('preprocessing', preprocessor),
    ('model', LinearRegression())
])


score = cross_val_score(pipeline, X, y, cv=5, scoring='r2').mean()
print("Pipeline R2:", score)


pipeline.fit(X, y)


X_test = test[num_features + cat_features]


test_predictions = pipeline.predict(X_test)


submission = pd.DataFrame({
    "id": test["id"],
    "exam_score": test_predictions
})

submission.to_csv("submission.csv", index=False)


submission.shape



